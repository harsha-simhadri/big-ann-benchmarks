
\begin{abstract}

The \href{https://big-ann-benchmarks.com/neurips23.html}{2023 Big ANN Challenge}, 
held at \href{https://neurips.cc/virtual/2023/competition/66587}{NeurIPS'23},
focused on advancing the state-of-the-art
in indexing data structures and search algorithms for practical variants of Approximate
Nearest Neighbor (ANN) search that reflect the growing complexity and diversity of workloads.
%
Unlike prior challenges that emphasized scaling up classical ANN search
~\cite{DBLP:conf/nips/SimhadriWADBBCH21}, this competition addressed filtered search, out-of-distribution data, sparse and streaming variants of ANNS.
%
Participants developed and submitted innovative solutions that were evaluated on
new standard datasets with constrained computational resources.
%
The results showcased significant improvements in search accuracy and efficiency over industry-standard baselines,
with notable contributions from both academic and industrial teams.
%
This paper summarizes the competition tracks, datasets, evaluation metrics, and the
innovative approaches of the top-performing submissions, providing insights into the 
current advancements and future directions in the field of ANN search.

% We propose a competition to encourage the development of indexing data structures and search algorithms
% for the Approximate Nearest Neighbor (ANN) or Vector search problem.
% Rather than evaluating the classical uniform indexing of dense vectors, where the only challenge is to scale up, this competition proposes to focus on difficult variants of the task. 
% Optimizing these variants is increasingly relevant as vector search becomes commonplace and the "simple" case is sufficiently well addressed. 
% Specifically, we propose the \emph{sparse}, \emph{filtered},  \emph{out-of-distribution} and \emph{streaming} variants of ANNS.
% These variants require adapted search algorithms and strategies with different tradeoffs. 
% This competition aims at being accessible to participants with modest compute resources by limiting the scale of the datasets, normalizing on limited evaluation hardware, and accepting open-source submissions to only a subset of the datasets.
% This competition will build on the evaluation framework\footnote{\url{https://github.com/harsha-simhadri/big-ann-benchmarks}}
% that we set up for the billion-scale ANNS challenge\footnote{\url{https://big-ann-benchmarks.com/}} of NeurIPS 2021.
% %organized by a subset of the organizers at NeurIPS 2021.
\end{abstract}